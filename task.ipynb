{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation', 'monkey_labels.txt', '10449_44567_upload_training.zip', '10449_44567_upload_validation.zip', 'training']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)\n",
      "matplotlib 3.2.1\n",
      "numpy 1.18.5\n",
      "pandas 1.0.4\n",
      "sklearn 0.23.1\n",
      "tensorflow 2.2.0\n",
      "tensorflow.keras 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "['n6', 'n5', 'n2', 'n1', 'n3', 'n0', 'n8', 'n7', 'n9', 'n4']\n",
      "['n6', 'n5', 'n2', 'n1', 'n3', 'n0', 'n8', 'n7', 'n9', 'n4']\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../input/training\"\n",
    "valid_dir = \"../input/validation\"\n",
    "label_file = \"../input/monkey_labels.txt\"\n",
    "print(os.path.exists(train_dir))\n",
    "print(os.path.exists(valid_dir))\n",
    "print(os.path.exists(label_file))\n",
    "\n",
    "print(os.listdir(train_dir))\n",
    "print(os.listdir(valid_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label     Latin Name              Common Name                     \\\n",
      "0  n0         alouatta_palliata\\t    mantled_howler                   \n",
      "1  n1        erythrocebus_patas\\t    patas_monkey                     \n",
      "2  n2        cacajao_calvus\\t        bald_uakari                      \n",
      "3  n3        macaca_fuscata\\t        japanese_macaque                 \n",
      "4  n4       cebuella_pygmea\\t        pygmy_marmoset                   \n",
      "5  n5       cebus_capucinus\\t        white_headed_capuchin            \n",
      "6  n6       mico_argentatus\\t        silvery_marmoset                 \n",
      "7  n7      saimiri_sciureus\\t        common_squirrel_monkey           \n",
      "8  n8       aotus_nigriceps\\t        black_headed_night_monkey        \n",
      "9  n9       trachypithecus_johnii    nilgiri_langur                   \n",
      "\n",
      "    Train Images    Validation Images  \n",
      "0             131                  26  \n",
      "1             139                  28  \n",
      "2             137                  27  \n",
      "3             152                  30  \n",
      "4             131                  26  \n",
      "5             141                  28  \n",
      "6             132                  26  \n",
      "7             142                  28  \n",
      "8             133                  27  \n",
      "9             132                  26  \n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(label_file, header=0)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1098 images belonging to 10 classes.\n",
      "Found 272 images belonging to 10 classes.\n",
      "1098 272\n"
     ]
    }
   ],
   "source": [
    "height = 128\n",
    "width = 128\n",
    "channels = 3\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "\n",
    "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest',\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size = (height, width),\n",
    "                                                   batch_size = batch_size,\n",
    "                                                   seed = 7,\n",
    "                                                   shuffle = True,\n",
    "                                                   class_mode = \"categorical\")\n",
    "valid_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "valid_generator = valid_datagen.flow_from_directory(valid_dir,\n",
    "                                                    target_size = (height, width),\n",
    "                                                    batch_size = batch_size,\n",
    "                                                    seed = 7,\n",
    "                                                    shuffle = False,\n",
    "                                                    class_mode = \"categorical\")\n",
    "train_num = train_generator.samples\n",
    "valid_num = valid_generator.samples\n",
    "print(train_num, valid_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 128, 128, 3) (64, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "(64, 128, 128, 3) (64, 10)\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    x, y = train_generator.next()\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,482,730\n",
      "Trainable params: 4,482,730\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "                        activation='relu', input_shape=[width, height, channels]),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, padding='same',\n",
    "                        activation='relu'),\n",
    "    keras.layers.MaxPool2D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(num_classes, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 2.2939 - accuracy: 0.1219 - val_loss: 2.2416 - val_accuracy: 0.2188\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 2.1129 - accuracy: 0.2176 - val_loss: 1.9551 - val_accuracy: 0.2383\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.9150 - accuracy: 0.2979 - val_loss: 2.0283 - val_accuracy: 0.3242\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.8138 - accuracy: 0.3104 - val_loss: 1.6677 - val_accuracy: 0.3789\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.7226 - accuracy: 0.3569 - val_loss: 2.0488 - val_accuracy: 0.2383\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.7916 - accuracy: 0.3598 - val_loss: 1.5886 - val_accuracy: 0.4219\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 45s 3s/step - loss: 1.6278 - accuracy: 0.4072 - val_loss: 1.7636 - val_accuracy: 0.3516\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 45s 3s/step - loss: 1.5783 - accuracy: 0.4188 - val_loss: 1.9200 - val_accuracy: 0.4023\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 45s 3s/step - loss: 1.5076 - accuracy: 0.4555 - val_loss: 1.5122 - val_accuracy: 0.4219\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.4884 - accuracy: 0.4574 - val_loss: 1.5737 - val_accuracy: 0.4531\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 45s 3s/step - loss: 1.4295 - accuracy: 0.4816 - val_loss: 1.3404 - val_accuracy: 0.5156\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.3866 - accuracy: 0.4836 - val_loss: 1.3065 - val_accuracy: 0.5586\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 1.3263 - accuracy: 0.5068 - val_loss: 1.3383 - val_accuracy: 0.5234\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.3627 - accuracy: 0.4923 - val_loss: 1.4710 - val_accuracy: 0.4453\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.2819 - accuracy: 0.5300 - val_loss: 1.2398 - val_accuracy: 0.5586\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.2937 - accuracy: 0.5309 - val_loss: 1.5015 - val_accuracy: 0.4727\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.2414 - accuracy: 0.5193 - val_loss: 1.1260 - val_accuracy: 0.6250\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.2962 - accuracy: 0.5300 - val_loss: 1.1833 - val_accuracy: 0.6055\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 1.2541 - accuracy: 0.5474 - val_loss: 1.3101 - val_accuracy: 0.5312\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.1904 - accuracy: 0.5706 - val_loss: 1.0621 - val_accuracy: 0.6797\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.1165 - accuracy: 0.5851 - val_loss: 1.1887 - val_accuracy: 0.5742\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 1.1468 - accuracy: 0.5716 - val_loss: 1.0241 - val_accuracy: 0.6289\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.1393 - accuracy: 0.5890 - val_loss: 1.1809 - val_accuracy: 0.5977\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.1784 - accuracy: 0.5841 - val_loss: 0.9655 - val_accuracy: 0.6719\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.1325 - accuracy: 0.5783 - val_loss: 1.1365 - val_accuracy: 0.6523\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.1046 - accuracy: 0.6219 - val_loss: 1.0666 - val_accuracy: 0.6328\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.0493 - accuracy: 0.6093 - val_loss: 1.0395 - val_accuracy: 0.6680\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 1.0279 - accuracy: 0.6354 - val_loss: 0.9539 - val_accuracy: 0.6680\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.9824 - accuracy: 0.6489 - val_loss: 1.3179 - val_accuracy: 0.5469\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 1.0561 - accuracy: 0.6199 - val_loss: 1.0523 - val_accuracy: 0.6445\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.9791 - accuracy: 0.6528 - val_loss: 1.0020 - val_accuracy: 0.6523\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.9291 - accuracy: 0.6431 - val_loss: 0.9299 - val_accuracy: 0.6992\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8678 - accuracy: 0.6944 - val_loss: 1.0546 - val_accuracy: 0.6641\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8932 - accuracy: 0.6770 - val_loss: 0.9130 - val_accuracy: 0.7109\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8848 - accuracy: 0.6857 - val_loss: 0.9757 - val_accuracy: 0.7031\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8352 - accuracy: 0.6973 - val_loss: 0.9177 - val_accuracy: 0.7344\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7917 - accuracy: 0.7108 - val_loss: 0.8953 - val_accuracy: 0.7031\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7995 - accuracy: 0.7108 - val_loss: 0.9727 - val_accuracy: 0.7031\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8074 - accuracy: 0.7050 - val_loss: 0.9141 - val_accuracy: 0.6992\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7540 - accuracy: 0.7273 - val_loss: 0.9358 - val_accuracy: 0.7227\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7464 - accuracy: 0.7263 - val_loss: 1.2718 - val_accuracy: 0.6445\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.8388 - accuracy: 0.6867 - val_loss: 0.9392 - val_accuracy: 0.7266\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.7283 - accuracy: 0.7244 - val_loss: 0.8761 - val_accuracy: 0.7461\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7502 - accuracy: 0.7195 - val_loss: 1.2359 - val_accuracy: 0.6367\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7210 - accuracy: 0.7398 - val_loss: 0.8956 - val_accuracy: 0.7422\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.7240 - accuracy: 0.7369 - val_loss: 0.9548 - val_accuracy: 0.7109\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.6960 - accuracy: 0.7553 - val_loss: 1.0618 - val_accuracy: 0.6953\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.6500 - accuracy: 0.7621 - val_loss: 0.8943 - val_accuracy: 0.7266\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.6847 - accuracy: 0.7621 - val_loss: 0.8721 - val_accuracy: 0.7109\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.6495 - accuracy: 0.7660 - val_loss: 1.0922 - val_accuracy: 0.6758\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.6498 - accuracy: 0.7718 - val_loss: 0.8769 - val_accuracy: 0.7188\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.6591 - accuracy: 0.7553 - val_loss: 0.9379 - val_accuracy: 0.7266\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.5870 - accuracy: 0.7794 - val_loss: 0.9618 - val_accuracy: 0.7148\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.6003 - accuracy: 0.7757 - val_loss: 0.9638 - val_accuracy: 0.7109\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5990 - accuracy: 0.7892 - val_loss: 0.8436 - val_accuracy: 0.7578\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5302 - accuracy: 0.8143 - val_loss: 0.8017 - val_accuracy: 0.7773\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5690 - accuracy: 0.8008 - val_loss: 0.8500 - val_accuracy: 0.7383\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5467 - accuracy: 0.7921 - val_loss: 1.2052 - val_accuracy: 0.6172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.7534 - accuracy: 0.7331 - val_loss: 0.8769 - val_accuracy: 0.6953\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.6198 - accuracy: 0.7776 - val_loss: 0.7883 - val_accuracy: 0.7383\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.5355 - accuracy: 0.8104 - val_loss: 0.8266 - val_accuracy: 0.7578\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.5027 - accuracy: 0.8211 - val_loss: 1.0427 - val_accuracy: 0.6797\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.5627 - accuracy: 0.7979 - val_loss: 0.8648 - val_accuracy: 0.7500\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5071 - accuracy: 0.8153 - val_loss: 0.8497 - val_accuracy: 0.7539\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4859 - accuracy: 0.8211 - val_loss: 0.8588 - val_accuracy: 0.7578\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4635 - accuracy: 0.8327 - val_loss: 1.0148 - val_accuracy: 0.6992\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.4801 - accuracy: 0.8366 - val_loss: 0.9430 - val_accuracy: 0.7266\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4825 - accuracy: 0.8288 - val_loss: 1.0247 - val_accuracy: 0.6953\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4933 - accuracy: 0.8075 - val_loss: 0.8285 - val_accuracy: 0.7578\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5846 - accuracy: 0.7901 - val_loss: 0.7139 - val_accuracy: 0.7852\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5267 - accuracy: 0.8066 - val_loss: 0.8079 - val_accuracy: 0.7500\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.5459 - accuracy: 0.8201 - val_loss: 0.7820 - val_accuracy: 0.7383\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 50s 3s/step - loss: 0.4971 - accuracy: 0.8250 - val_loss: 0.9163 - val_accuracy: 0.7227\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4011 - accuracy: 0.8607 - val_loss: 0.8743 - val_accuracy: 0.7617\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4911 - accuracy: 0.8317 - val_loss: 0.7716 - val_accuracy: 0.7461\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4940 - accuracy: 0.8201 - val_loss: 0.8106 - val_accuracy: 0.7734\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4093 - accuracy: 0.8501 - val_loss: 0.7358 - val_accuracy: 0.7891\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.3898 - accuracy: 0.8665 - val_loss: 1.0535 - val_accuracy: 0.6797\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4454 - accuracy: 0.8453 - val_loss: 0.7193 - val_accuracy: 0.7812\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4315 - accuracy: 0.8453 - val_loss: 0.6591 - val_accuracy: 0.8008\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.3921 - accuracy: 0.8617 - val_loss: 0.6809 - val_accuracy: 0.8008\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.3615 - accuracy: 0.8685 - val_loss: 0.7536 - val_accuracy: 0.7930\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3211 - accuracy: 0.8772 - val_loss: 0.9420 - val_accuracy: 0.7500\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.3749 - accuracy: 0.8750 - val_loss: 0.8212 - val_accuracy: 0.7656\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.4124 - accuracy: 0.8607 - val_loss: 0.7525 - val_accuracy: 0.7930\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.4131 - accuracy: 0.8656 - val_loss: 0.8388 - val_accuracy: 0.7656\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3027 - accuracy: 0.8907 - val_loss: 1.0296 - val_accuracy: 0.7344\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.3366 - accuracy: 0.8781 - val_loss: 0.8567 - val_accuracy: 0.7812\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3749 - accuracy: 0.8723 - val_loss: 0.8501 - val_accuracy: 0.7930\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.3726 - accuracy: 0.8627 - val_loss: 0.9657 - val_accuracy: 0.7266\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3010 - accuracy: 0.8830 - val_loss: 0.8569 - val_accuracy: 0.8047\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3834 - accuracy: 0.8791 - val_loss: 0.8080 - val_accuracy: 0.7891\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3405 - accuracy: 0.8781 - val_loss: 0.8513 - val_accuracy: 0.7969\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.4018 - accuracy: 0.8549 - val_loss: 1.0274 - val_accuracy: 0.7500\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3313 - accuracy: 0.8752 - val_loss: 0.7791 - val_accuracy: 0.8086\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2503 - accuracy: 0.9120 - val_loss: 0.9136 - val_accuracy: 0.7891\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2742 - accuracy: 0.9023 - val_loss: 0.8515 - val_accuracy: 0.7734\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3081 - accuracy: 0.8936 - val_loss: 0.9355 - val_accuracy: 0.7578\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.2864 - accuracy: 0.8985 - val_loss: 0.7180 - val_accuracy: 0.8281\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3014 - accuracy: 0.8985 - val_loss: 1.1747 - val_accuracy: 0.6875\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.4119 - accuracy: 0.8569 - val_loss: 0.6758 - val_accuracy: 0.8203\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3093 - accuracy: 0.8849 - val_loss: 0.6755 - val_accuracy: 0.7930\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2507 - accuracy: 0.9110 - val_loss: 0.9584 - val_accuracy: 0.7344\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.2552 - accuracy: 0.9081 - val_loss: 0.9345 - val_accuracy: 0.7656\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.4095 - accuracy: 0.8511 - val_loss: 0.9606 - val_accuracy: 0.7227\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3162 - accuracy: 0.8897 - val_loss: 0.7291 - val_accuracy: 0.7773\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3138 - accuracy: 0.8839 - val_loss: 0.6959 - val_accuracy: 0.8164\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.3151 - accuracy: 0.8956 - val_loss: 1.0189 - val_accuracy: 0.7266\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.3002 - accuracy: 0.8965 - val_loss: 0.6850 - val_accuracy: 0.8164\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.2363 - accuracy: 0.9237 - val_loss: 0.8776 - val_accuracy: 0.7734\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2197 - accuracy: 0.9284 - val_loss: 1.1445 - val_accuracy: 0.7148\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2568 - accuracy: 0.9110 - val_loss: 1.0396 - val_accuracy: 0.7305\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2166 - accuracy: 0.9207 - val_loss: 0.8484 - val_accuracy: 0.8125\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1724 - accuracy: 0.9352 - val_loss: 0.8183 - val_accuracy: 0.8164\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1843 - accuracy: 0.9400 - val_loss: 0.9780 - val_accuracy: 0.7695\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.1930 - accuracy: 0.9410 - val_loss: 0.7952 - val_accuracy: 0.7852\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2060 - accuracy: 0.9304 - val_loss: 1.0270 - val_accuracy: 0.7539\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2025 - accuracy: 0.9362 - val_loss: 1.1081 - val_accuracy: 0.7383\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1496 - accuracy: 0.9449 - val_loss: 0.7956 - val_accuracy: 0.8242\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1772 - accuracy: 0.9323 - val_loss: 0.9426 - val_accuracy: 0.7773\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2201 - accuracy: 0.9284 - val_loss: 1.0225 - val_accuracy: 0.7539\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2075 - accuracy: 0.9207 - val_loss: 0.9096 - val_accuracy: 0.7773\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.1471 - accuracy: 0.9522 - val_loss: 0.9205 - val_accuracy: 0.8086\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2802 - accuracy: 0.9130 - val_loss: 0.9466 - val_accuracy: 0.8047\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2231 - accuracy: 0.9255 - val_loss: 1.0056 - val_accuracy: 0.7930\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1992 - accuracy: 0.9333 - val_loss: 0.8248 - val_accuracy: 0.8086\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 50s 3s/step - loss: 0.2065 - accuracy: 0.9333 - val_loss: 0.9490 - val_accuracy: 0.8281\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1365 - accuracy: 0.9594 - val_loss: 0.9437 - val_accuracy: 0.8359\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.1987 - accuracy: 0.9352 - val_loss: 0.7555 - val_accuracy: 0.7930\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.3166 - accuracy: 0.8956 - val_loss: 0.7686 - val_accuracy: 0.7930\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.2604 - accuracy: 0.9014 - val_loss: 0.7712 - val_accuracy: 0.8125\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2049 - accuracy: 0.9255 - val_loss: 0.7305 - val_accuracy: 0.8281\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2191 - accuracy: 0.9226 - val_loss: 0.8566 - val_accuracy: 0.8008\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1779 - accuracy: 0.9410 - val_loss: 0.8678 - val_accuracy: 0.7891\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1288 - accuracy: 0.9545 - val_loss: 0.9064 - val_accuracy: 0.8125\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1750 - accuracy: 0.9420 - val_loss: 0.8211 - val_accuracy: 0.8477\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1579 - accuracy: 0.9400 - val_loss: 0.8138 - val_accuracy: 0.8359\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1277 - accuracy: 0.9603 - val_loss: 0.6594 - val_accuracy: 0.8555\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1858 - accuracy: 0.9333 - val_loss: 0.8409 - val_accuracy: 0.8281\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1625 - accuracy: 0.9391 - val_loss: 1.1154 - val_accuracy: 0.7539\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1816 - accuracy: 0.9342 - val_loss: 0.8383 - val_accuracy: 0.7969\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1401 - accuracy: 0.9478 - val_loss: 1.0783 - val_accuracy: 0.7812\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1826 - accuracy: 0.9507 - val_loss: 0.7428 - val_accuracy: 0.8438\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.1578 - accuracy: 0.9449 - val_loss: 0.7472 - val_accuracy: 0.8242\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1306 - accuracy: 0.9613 - val_loss: 0.7362 - val_accuracy: 0.8008\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 50s 3s/step - loss: 0.1031 - accuracy: 0.9632 - val_loss: 0.8576 - val_accuracy: 0.8125\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1183 - accuracy: 0.9545 - val_loss: 0.8752 - val_accuracy: 0.8438\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1252 - accuracy: 0.9632 - val_loss: 0.8586 - val_accuracy: 0.8047\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1588 - accuracy: 0.9381 - val_loss: 1.1913 - val_accuracy: 0.7812\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1858 - accuracy: 0.9352 - val_loss: 0.9103 - val_accuracy: 0.7930\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1801 - accuracy: 0.9352 - val_loss: 0.7901 - val_accuracy: 0.8242\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1798 - accuracy: 0.9323 - val_loss: 0.9919 - val_accuracy: 0.7656\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1824 - accuracy: 0.9400 - val_loss: 1.2140 - val_accuracy: 0.7344\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2053 - accuracy: 0.9197 - val_loss: 1.0662 - val_accuracy: 0.7305\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1938 - accuracy: 0.9342 - val_loss: 0.9263 - val_accuracy: 0.7969\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1743 - accuracy: 0.9478 - val_loss: 0.7620 - val_accuracy: 0.8320\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.1361 - accuracy: 0.9485 - val_loss: 0.9081 - val_accuracy: 0.8281\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1019 - accuracy: 0.9632 - val_loss: 1.0021 - val_accuracy: 0.8008\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1110 - accuracy: 0.9691 - val_loss: 0.9394 - val_accuracy: 0.8125\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1005 - accuracy: 0.9623 - val_loss: 0.8442 - val_accuracy: 0.8125\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0853 - accuracy: 0.9671 - val_loss: 1.1393 - val_accuracy: 0.7773\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1939 - accuracy: 0.9323 - val_loss: 0.9754 - val_accuracy: 0.7852\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1935 - accuracy: 0.9381 - val_loss: 0.9921 - val_accuracy: 0.8008\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1347 - accuracy: 0.9507 - val_loss: 0.8122 - val_accuracy: 0.8086\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1646 - accuracy: 0.9439 - val_loss: 0.8383 - val_accuracy: 0.8281\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.2528 - accuracy: 0.9226 - val_loss: 0.6681 - val_accuracy: 0.8555\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1879 - accuracy: 0.9333 - val_loss: 0.7269 - val_accuracy: 0.8125\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1161 - accuracy: 0.9584 - val_loss: 0.7247 - val_accuracy: 0.8398\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1022 - accuracy: 0.9671 - val_loss: 0.7084 - val_accuracy: 0.8594\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.0953 - accuracy: 0.9623 - val_loss: 0.8321 - val_accuracy: 0.8320\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1033 - accuracy: 0.9691 - val_loss: 0.7983 - val_accuracy: 0.8398\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.0933 - accuracy: 0.9720 - val_loss: 0.8563 - val_accuracy: 0.8203\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 47s 3s/step - loss: 0.1399 - accuracy: 0.9526 - val_loss: 1.1499 - val_accuracy: 0.8203\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1249 - accuracy: 0.9613 - val_loss: 0.8099 - val_accuracy: 0.8242\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.0817 - accuracy: 0.9724 - val_loss: 0.8675 - val_accuracy: 0.8281\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 50s 3s/step - loss: 0.1040 - accuracy: 0.9681 - val_loss: 0.7827 - val_accuracy: 0.8438\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1428 - accuracy: 0.9584 - val_loss: 0.7144 - val_accuracy: 0.8594\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.1286 - accuracy: 0.9586 - val_loss: 0.7377 - val_accuracy: 0.8438\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1141 - accuracy: 0.9691 - val_loss: 0.9451 - val_accuracy: 0.8203\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0754 - accuracy: 0.9797 - val_loss: 0.7745 - val_accuracy: 0.8359\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1094 - accuracy: 0.9652 - val_loss: 1.1573 - val_accuracy: 0.7930\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.1072 - accuracy: 0.9632 - val_loss: 0.8418 - val_accuracy: 0.8281\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1430 - accuracy: 0.9507 - val_loss: 1.0611 - val_accuracy: 0.8125\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1359 - accuracy: 0.9555 - val_loss: 0.7457 - val_accuracy: 0.8320\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.1055 - accuracy: 0.9632 - val_loss: 0.8056 - val_accuracy: 0.8242\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.0939 - accuracy: 0.9681 - val_loss: 1.0264 - val_accuracy: 0.8242\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0810 - accuracy: 0.9768 - val_loss: 0.8799 - val_accuracy: 0.8164\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0884 - accuracy: 0.9720 - val_loss: 0.9375 - val_accuracy: 0.8320\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1335 - accuracy: 0.9584 - val_loss: 1.0277 - val_accuracy: 0.8008\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.1359 - accuracy: 0.9487 - val_loss: 0.7819 - val_accuracy: 0.8477\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1177 - accuracy: 0.9632 - val_loss: 1.0938 - val_accuracy: 0.8008\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1682 - accuracy: 0.9449 - val_loss: 1.0037 - val_accuracy: 0.7891\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 49s 3s/step - loss: 0.1286 - accuracy: 0.9555 - val_loss: 0.7595 - val_accuracy: 0.8711\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.1038 - accuracy: 0.9594 - val_loss: 0.7315 - val_accuracy: 0.8398\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1592 - accuracy: 0.9478 - val_loss: 0.9590 - val_accuracy: 0.7812\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0900 - accuracy: 0.9691 - val_loss: 0.8691 - val_accuracy: 0.8281\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.1191 - accuracy: 0.9623 - val_loss: 0.8896 - val_accuracy: 0.8516\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1406 - accuracy: 0.9516 - val_loss: 0.8778 - val_accuracy: 0.8281\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.1066 - accuracy: 0.9662 - val_loss: 0.9050 - val_accuracy: 0.8555\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1791 - accuracy: 0.9449 - val_loss: 1.0422 - val_accuracy: 0.7930\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1308 - accuracy: 0.9545 - val_loss: 0.7460 - val_accuracy: 0.8438\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1048 - accuracy: 0.9642 - val_loss: 0.9764 - val_accuracy: 0.8281\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 50s 3s/step - loss: 0.1067 - accuracy: 0.9613 - val_loss: 0.8642 - val_accuracy: 0.8125\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.1103 - accuracy: 0.9642 - val_loss: 0.7386 - val_accuracy: 0.8555\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 46s 3s/step - loss: 0.0834 - accuracy: 0.9768 - val_loss: 0.8857 - val_accuracy: 0.8125\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0625 - accuracy: 0.9778 - val_loss: 0.8220 - val_accuracy: 0.8320\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0718 - accuracy: 0.9778 - val_loss: 1.0157 - val_accuracy: 0.7891\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0611 - accuracy: 0.9768 - val_loss: 0.8794 - val_accuracy: 0.8242\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0697 - accuracy: 0.9758 - val_loss: 1.2287 - val_accuracy: 0.8086\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0949 - accuracy: 0.9691 - val_loss: 0.8597 - val_accuracy: 0.8359\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 47s 3s/step - loss: 0.0787 - accuracy: 0.9720 - val_loss: 0.8828 - val_accuracy: 0.8164\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 48s 3s/step - loss: 0.0587 - accuracy: 0.9825 - val_loss: 0.9852 - val_accuracy: 0.8320\n",
      "Epoch 213/300\n",
      " 7/17 [===========>..................] - ETA: 23s - loss: 0.0810 - accuracy: 0.9645"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = train_num // batch_size,\n",
    "                              epochs = epochs,\n",
    "                              validation_data = valid_generator,\n",
    "                              validation_steps = valid_num // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history, label, epcohs, min_value, max_value):\n",
    "    data = {}\n",
    "    data[label] = history.history[label]\n",
    "    data['val_'+label] = history.history['val_'+label]\n",
    "    pd.DataFrame(data).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    plt.axis([0, epochs, min_value, max_value])\n",
    "    plt.show()\n",
    "plot_learning_curves(history, 'accuracy', epochs, 0, 1)\n",
    "plot_learning_curves(history, 'loss', epochs, 1.5, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
